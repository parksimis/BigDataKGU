# -*- coding: utf-8 -*-
"""2020-07-17 Regularized Regression

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M-myZXQWVoZvLRv4_dXjrkW1lDCrtImw

# 정규화 회귀분석 실습

python의 scikit-learn 패키지를 이용해 정규화 회귀분석을 직접 실행

## 데이터 불러오기 및 분할하기

 다중 회귀분석과 동일한 데이터에 대해 분석
"""

from sklearn import datasets
data = datasets.load_diabetes()

x = data['data']
y = data['target']

print(x.shape, y.shape)

from sklearn.model_selection import train_test_split

# 데이터 나누기 - 6:2:2 비율
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1)

print(x_train.shape, x_val.shape, x_test.shape)

"""## 모델 학습하기

Training data를 이용해 각 모델을 학습해 보자. 먼저 아래와 같이 각 모델을 import
"""

from sklearn.linear_model import Ridge, Lasso, ElasticNet

"""[Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html?highlight=ridge#sklearn.linear_model.Ridge), [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html?highlight=lasso#sklearn.linear_model.Lasso), [ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html?highlight=elasticnet#sklearn.linear_model.ElasticNet) 에 대한 자세한 설명은 링크를 참조하자. 이를 보고 적절한 hyperparameter를 이용해 각 모델을 구현해 보자."""

# TODO : Ridge, Lasso, ElasticNet 모델 객체 생성하기

ridge = Ridge()
lasso = Lasso()
elastic = ElasticNet()

# TODO : 각 모델 학습하기

ridge.fit(x_train, y_train)
lasso.fit(x_train, y_train)
elastic.fit(x_train, y_train)

"""### 결과 분석하기

각 모델의 설명력을 확인해보저.  
지난 번에 사용한 r2_score를 이용할 수 있지만, 각 모델에서 제공하는 ```score```함수를 이용해 R-Square 점수를 얻을 수도 있다.
"""

# TODO: Ridge 모델의 training & validation data에 대한 R-square 계산하기
ridge_train_r2 = ridge.score(x_train, y_train)
ridge_val_r2 = ridge.score(x_val, y_val)
print ("Ridge training R-square: {:.4f}".format(ridge_train_r2))
print ("Ridge validation R-square: {:.4f}".format(ridge_val_r2))

# TODO: Lasso 모델의 training & validation data에 대한 R-square 계산하기
lasso_train_r2 = lasso.score(x_train, y_train)
lasso_val_r2 =lasso.score(x_val, y_val)
print ("Lasso training R-square: {:.4f}".format(lasso_train_r2))
print ("Lasso validation R-square: {:.4f} " .format(lasso_val_r2))

# TODO: ElasticNet 모델의 training & validation data에 대한 R-square 계산하기
elastic_train_r2 = elastic.score(x_train, y_train)
elastic_val_r2 = elastic.score(x_val, y_val)
print ("ElasticNet training R-square: {:.4f}".format(elastic_train_r2))
print ("ElasticNet validation R-square: {:.4f} " .format(elastic_val_r2))

"""수업 시간에 배운 Ridge와 Lasso의 가장 큰 차이점은 바로 변수를 선택할 수 있는지에 대한 여부였다. 각 모델의 회귀계수 값을 불러와 0이 아닌 회귀계수가 몇 개인지, 즉 회귀분석에 선택된 변수가 몇 개인지 세어 보자."""

# TODO: 각 모델이 사용한 변수의 개수 세어보기
import numpy as np
ridge_used_variables = np.sum(ridge.coef_ != 0)
lasso_used_variables = np.sum(lasso.coef_ != 0)
elastic_used_variables = np.sum(elastic.coef_ != 0)
print("Used variables: Ridge vs Lasso vs ElasticNet = %d vs %d vs %d" % (ridge_used_variables, lasso_used_variables, elastic_used_variables))

"""배웠던 내용대로, Lasso와 ElasticNet의 경우 변수를 선택하여 모델을 학습했다는 것을 알 수 있다. Lasso의 파라미터 중 하나인 alpha(수업에서의 lambda)를 변화시켜 보면서, 선택한 변수의 개수가 어떻게 달라지는지 확인해 보자."""

alpha_list = [0.001, 0.01, 0.1, 1, 10, 100]
for alpha in alpha_list:
    # TODO: 각 alpha를 이용한 Lasso 모델의 training & validation data에 대한 R-square 및 변수 개수 계산하기
    lasso = Lasso(alpha=alpha).fit(x_train, y_train)
    lasso_train_score = lasso.score(x_train, y_train)
    lasso_val_score = lasso.score(x_val, y_val)
    lasso_used_variables = np.sum(lasso.coef_ != 0)
    
    print(f"======================= alpha={alpha} =======================")
    print(f"training score: {lasso_train_score :.4f}")
    print(f"test score: {lasso_val_score :.4f}")
    print(f"number of features used: {lasso_used_variables}")
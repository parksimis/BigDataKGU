{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020-07-21 Ensemble.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJXqPm0U2Vy7"
      },
      "source": [
        "## 앙상블 실습\n",
        "\n",
        "앙상블을 한 마디로 표현하면 **집단지성**으로, 여러 가지 모델을 결합해 최종 예측을 진행한다. 주로 variance를 줄이는데 큰 역할을 하는 앙상블은 대부분의 task에서 성능이 매우 뛰어난 방법론이라 알려져 있다.\n",
        "\n",
        "### **합의 기반 결합**\n",
        "\n",
        "앙상블 방법론은 머신 러닝 모델의 결합 방법에 따라 합의 기반 결합과 학습 기반 결합으로 나눌 수 있다. \n",
        "  \n",
        "  \n",
        "합의 기반 결합은 쉽게 말해 **다수결**을 이용하는 것이다. 단순한 예로, 70%의 정확도를 가지는 모델이 5개 있다고 하자.  \n",
        "만약 이들이 서로 독립이라면, 이들의 결과로 다수결 투표를 진행했을 때의 정확도는 83.7%에 달한다.  \n",
        "  \n",
        "이 때 중요한 것은 모델들이 서로 **독립**이어야 한다는 것이다.(**서로 관련이 없어야 함.**) 독립이 아니라 똑같은 모델 5개이면 다수결을 해도 정확도는 70%에서 변하지 않는다. 따라서 합의 기반 결합에서는 서로 독립인, 혹은 다양한 특징을 갖는 모델들을 생성해야 한다는 것이 매우 중요하다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWiDHfVk4a-q"
      },
      "source": [
        "### **합의 기반 결합 - Voting**\n",
        "\n",
        "Voting 기법은 말 그대로 여러 개의 모델에게 정답이 무엇인지 투표시키는 방식을 말한다. 이 때 각 모델은 서로 다른 방법론을 통해 만들어진다. python의 scikit-learn 패키지의 [VotingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html?highlight=votingclassifier#sklearn.ensemble.VotingClassifier) 를 이용해 기본적인 voting 방법론을 직접 실행해보자.\n",
        "  \n",
        "  \n",
        "[Covertype](https://archive.ics.uci.edu/ml/datasets/Covertype) 데이터셋을 사용해 보자. Scikit-learn의 [fetch_covtype](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_covtype.html#sklearn.datasets.fetch_covtype) 함수로 데이터를 받아올 수 있다.  \n",
        "  \n",
        "숲의 Covertype 분류\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBZ_iKJd19Bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0a6abf8-1aea-4478-e1fb-59e246222084"
      },
      "source": [
        "from sklearn.datasets import fetch_covtype\n",
        "\n",
        "x, y = fetch_covtype(return_X_y=True)\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://ndownloader.figshare.com/files/5976039\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(581012, 54)\n",
            "(581012,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVabqgug5eBo"
      },
      "source": [
        "58만개의 인스턴스는 너무 많아 2000개만 사용\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOAh3QsC5Lyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16349e73-8ec2-4d17-ac17-14f473e9691c"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 나누기\n",
        "num_use_data = 2000\n",
        "x = x[:num_use_data, :]\n",
        "y = y[:num_use_data]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
        "\n",
        "print(x_train.shape, x_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1600, 54) (400, 54)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOLYBa4E5w0a"
      },
      "source": [
        "VotingClassifier를 학습하기 위해, 수업에서 배웠던 세 가지 분류기들을 이용해 보자. 먼저 필요한 모델들을 import 한 후 각각 생성하자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDXnSJHU5dXr"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLZkRapu5yK8"
      },
      "source": [
        "# 모델 객체 생성하기\n",
        "log_clf = LogisticRegression()\n",
        "dt_clf = DecisionTreeClassifier(random_state=1)\n",
        "svm_clf = SVC()\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lr', log_clf), \n",
        "                ('dt', dt_clf), \n",
        "                ('svc', svm_clf)])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJm9WsyR55yB"
      },
      "source": [
        "VotingClassifier의 모델을 위해, \n",
        "estimator 하이퍼파라미터를 작성  \n",
        "```estimator``` : estimatorslist of (str, estimator) tuples  \n",
        "각 모델들을 학습시킨 후 정확도를 비교."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqEpLwcM55Yj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dba9e7a-3222-454c-ffb3-e8ac3adf01d2"
      },
      "source": [
        "# 각 모델 학습 및 정확도 확인하기\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") # 경고가 뜨는 것을 무시\n",
        "\n",
        "voting_clf.fit(x_train, y_train)\n",
        "pred_test = voting_clf.predict(x_test)\n",
        "print(f'voting accuracy: {accuracy_score(y_test, pred_test)}')\n",
        "\n",
        "for name, estimator in voting_clf.named_estimators_.items():\n",
        "  estimator.fit(x_train, y_train)\n",
        "  pred_test_estim = estimator.predict(x_test)\n",
        "  print(f'{name}: {accuracy_score(y_test, pred_test_estim)}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "voting accuracy: 0.69\n",
            "lr: 0.615\n",
            "dt: 0.7475\n",
            "svc: 0.605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCjwcx3J63gS"
      },
      "source": [
        "VotingClassifier의 파라미터 중 하나인 voting은 다수결의 방식을 뜻한다. Default인 'hard'는 각 모델이 표를 하나씩 행사하는 방식이며, 'soft'는 각 모델의 분류 확률을 모두 더해 가장 높은 확률로 예측하는 방식이다. 일반적으로 soft voting 방식이 더 효과가 좋다고 알려져 있다. 이를 구현하고 위의 hard voting 방식과 비교해 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hSIqIi_6q_F"
      },
      "source": [
        "# To-Do : Soft Voting 방식으로 모델 생성.\n",
        "\n",
        "log_clf2 = LogisticRegression()\n",
        "dt_clf2 = DecisionTreeClassifier(random_state=1)\n",
        "svm_clf2 = SVC(probability=True)\n",
        "\n",
        "voting_clf2 = VotingClassifier(\n",
        "    estimators=[('lr', log_clf2), \n",
        "                ('dt', dt_clf2), \n",
        "                ('svc', svm_clf2)],\n",
        "                voting='soft')\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XssOVyF8aeC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a387c60-2ca1-465e-f35e-4c8d1207bbf1"
      },
      "source": [
        "# To-Do : Soft Voting 방식으로 생성한 모델 학습\n",
        "\n",
        "voting_clf2.fit(x_train, y_train)\n",
        "pred_test = voting_clf2.predict(x_test)\n",
        "print(f'voting accuracy: {accuracy_score(y_test, pred_test)}')\n",
        "\n",
        "for name, estimator in voting_clf2.named_estimators_.items():\n",
        "  estimator.fit(x_train, y_train)\n",
        "  pred_test_estim = estimator.predict(x_test)\n",
        "  print(f'{name}: {accuracy_score(y_test, pred_test_estim)}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "voting accuracy: 0.7675\n",
            "lr: 0.615\n",
            "dt: 0.7475\n",
            "svc: 0.605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApuM6DWK81O6"
      },
      "source": [
        "```predict_proba is not available when  probability=False```라는 경고문구가 뜨는데, 이는 SVM은 단순히 결정경계를 만들어주기 때문에 확률을 계산할 수 없기 때문이다. 따라서 SVM에서 확률 옵션을 켜주어야 가능하다. \n",
        "(```probability=False```)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFOHeLNQ9KBW"
      },
      "source": [
        "### **합의 기반 결합 - Bagging**\n",
        "---\n",
        "Bagging 기법은 voting과 달리 하나의 머신 러닝 방법론을 사용하지만, 주어진 학습 데이터나 변수를 모두 사용하지 않고 임의로 추출하여 다양한 모델을 학습시킨 후 이들의 합의 기반 결합을 진행한다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGxIhJ7j9hZA"
      },
      "source": [
        "Bagging의 종류는 각 모델의 학습용 데이터를 어떻게 구성하느냐에 따라 아래의 네 가지로 구분지을 수 있다.\n",
        "\n",
        "\n",
        "* Pasting: 같은 데이터를 중복해서 추출하지 않음\n",
        "* Bagging: 같은 데이터 샘플을 중복해서 추출\n",
        "* Random Subspace: 데이터가 아니라 주어진 독립 변수 중 일부를 랜덤 추출\n",
        "* Random Patches: 데이터와 독립 변수 모두 랜덤 추출해서 사용\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enD_85aU9HHi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a502440a-821f-4c1a-ead9-445b07692f6b"
      },
      "source": [
        "tree_clf = DecisionTreeClassifier(random_state=1)\n",
        "tree_clf.fit(x_train, y_train)\n",
        "pred_test = tree_clf.predict(x_test)\n",
        "print(f'normal DecisonTree accuracy: {accuracy_score(y_test, pred_test)}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "normal DecisonTree accuracy: 0.7475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAGV2gc0-USy"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z39n2kSK-V92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "537d2c22-9087-4bcb-f385-9f4240d6082d"
      },
      "source": [
        "# TODO: BaggingClassifier를 사용해 의사결정 나무 분류기 학습 및 정확도 계산하기\n",
        "\n",
        "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=300, \n",
        "                            max_samples=500, random_state=1)\n",
        "bag_clf.fit(x_train, y_train)\n",
        "pred_test_bag = bag_clf.predict(x_test)\n",
        "\n",
        "print(f'Bagging Classifier accuracy: {accuracy_score(y_test, pred_test_bag)}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bagging Classifier accuracy: 0.845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7tobpTk_fof"
      },
      "source": [
        "의사결정 나무에서 배운 재귀적 분기에 대해 떠올려보자. 분기를 할 후보들을 각 독립 변수들로 정렬한 후에 최적의 분기점을 불순도 함수를 이용해 찾는다고 배웠다. 이 때, 모든 독립 변수를 사용하는 것이 아니라 **일부**만을 골라 분기 후보를 찾는다면, 더 빠른 계산이 가능하다. 이것이 바로 위에서 말한 random subspace 혹은 random patches의 개념을 적용한 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYFVvNHn_idk"
      },
      "source": [
        "즉, random patches를 의사결정 나무에 사용한 것이 바로 RandomForest 이다. Scikit-learn 에서는 [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=randomforest#sklearn.ensemble.RandomForestClassifier)에서 이 모델을 제공하고 있으니, 이를 사용해서 분류해 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW2AKLJI_e81"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBrUY4Ot_pDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d6280bc-4af0-4428-c5f8-66b2e935c1ce"
      },
      "source": [
        "# To-Do : RandomForestClassifier를 사용해 분류기 학습 및 정확도 계산하기\n",
        "\n",
        "rf_clf = RandomForestClassifier(n_estimators=300, random_state=1)\n",
        "rf_clf.fit(x_train, y_train)\n",
        "pred_test_rf = rf_clf.predict(x_test)\n",
        "\n",
        "print(f'RandomForest Classifier accuracy: {accuracy_score(y_test, pred_test_rf)}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForest Classifier accuracy: 0.8425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BlIFJl7AISX"
      },
      "source": [
        "GridSearchCV를 이용해 최고의 파리미터 조합을 찾아보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHykyvQFANZz"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A16IEvSAZWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69a8e226-1128-4f49-9ab0-126930da7771"
      },
      "source": [
        "# To-Do : GridSearchCV를 이용해 최적의 조합을 찾고 그 때의 정확도 계산하기\n",
        "n_estimators = [100, 200, 300]\n",
        "max_features = ['auto', 0.2, 0.5]\n",
        "min_samples_leaf = [1, 5]\n",
        "max_depth = [None, 10]\n",
        "max_samples = [1000]\n",
        "param_grid = {\"n_estimators\" : n_estimators, \n",
        "              'max_features' : max_features,\n",
        "              'min_samples_leaf' : min_samples_leaf,\n",
        "              'max_depth' : max_depth,\n",
        "              'max_samples' : max_samples}\n",
        "              \n",
        "grid_search = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, \n",
        "                           scoring='accuracy')\n",
        "\n",
        "grid_search.fit(x_train, y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'max_depth': [None, 10],\n",
              "                         'max_features': ['auto', 0.2, 0.5],\n",
              "                         'max_samples': [1000], 'min_samples_leaf': [1, 5],\n",
              "                         'n_estimators': [100, 200, 300]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6DBfesnCM0M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96633739-0912-4a3c-9489-1b15dd43d5ba"
      },
      "source": [
        "print(grid_search.best_params_)\n",
        "pred_test_grid = grid_search.best_estimator_.predict(x_test)\n",
        "print(f'GridSearch RandomForest accuracy: {accuracy_score(y_test, pred_test_grid)}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'max_depth': None, 'max_features': 0.5, 'max_samples': 1000, 'min_samples_leaf': 1, 'n_estimators': 200}\n",
            "GridSearch RandomForest accuracy: 0.855\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}